# **光學字元辨識 (OCR) 總覽**

**光學字元辨識（Optical Character Recognition, OCR）** 是一種將影像中的文字內容轉換為電腦可理解、可儲存與可搜尋的文字資料的技術。透過 OCR，電腦能夠模擬人眼與人腦的行為來「閱讀」文字影像，如掃描的文件、街景照片、書寫筆跡、印刷報表等，進而轉換為可編輯、可分析的數位文字。

OCR 廣泛應用於：

- 文件自動化輸入（如發票、表單、契約的掃描識別）
- 車牌辨識（ALPR）
- 金融票據處理（如支票）
- 數位化歷史書籍與報紙
- 螢幕文字擷取、機器翻譯與輔助工具

### **傳統 OCR 流程與限制**

傳統 OCR 方法主要採用規則式影像處理技術與分類器模型，依賴逐步管線處理方式：

1. **影像預處理**：包括灰階轉換、二值化、去雜訊、傾斜校正與自適應對比調整等，目的是提高辨識準確率。
2. **文字區塊偵測（Text Detection）**：偵測出文字區域（如文字行、段落或文字框）
3. **字元分割（Character Segmentation）**：將文字區塊拆分成單一字元影像。
4. **字元辨識（Character Recognition）**：使用機器學習模型（如 SVM、KNN）或模板匹配進行辨識。
5. **後處理**：根據語言規則與字典檢查進行錯誤修正，例如拼字校正、語法修復等。

**限制與挑戰**：

- 字元分割對手寫、連體字、多樣化字體極度敏感。
- 任何前段步驟的誤差都會累積至最終輸出。
- 無法適應自然場景、斜體字、背景干擾、旋轉或複雜排列。

這使得傳統 OCR 方法在真實世界應用中表現有限，因此近年來逐漸被深度學習模型取代。

---

# CNN + LSTM + CTC 架構原理

這種架構整合了三種強大的技術，使其能夠直接從輸入的文字影像，一次性地輸出整串文字序列，無需進行麻煩的字元切割。

## 1\. 卷積神經網路 (CNN) - 特徵擷取器

**功能**：CNN 的主要任務是從輸入的影像中 **擷取高維度的視覺特徵 (Visual Features)**。

**原理架構**：

- **卷積層 (Convolutional Layers)**：透過多個卷積核 (Filter) 在影像上滑動，偵測影像中的局部特徵，例如邊緣、角落、紋理等。隨著網路層數加深，CNN 能組合這些低階特徵，形成更複雜的特徵，例如筆劃、部首，甚至是完整的字元形狀。
- **池化層 (Pooling Layers)**：通常接在卷積層之後，用來縮減特徵圖 (Feature Map) 的尺寸，保留最重要的特徵資訊，同時減少計算量並增加模型的穩定性。最常見的是最大池化 (Max Pooling)。
- **批次正規化 (Batch Normalization)**：加速模型訓練，並提高模型的泛化能力。

在 OCR 任務中，輸入的文字影像會先經過一個深度 CNN (例如 VGG、ResNet 或客製化的小型 CNN)。這個網路的輸出不再是一個單一的分類結果，而是一系列的 **特徵序列 (Feature Sequence)**。通常，我們會將影像縮放至固定高度，但保留可變的寬度。CNN 處理後，會輸出一系列沿著影像寬度方向排列的特徵向量。每個特徵向量可以看作是影像中一個垂直切片 (frame) 的抽象表示。

## 2\. 長短期記憶模型 (LSTM) - 序列資訊處理器

**功能**：LSTM 是一種遞歸神經網路 (Recurrent Neural Network, RNN)，特別擅長 **處理和學習序列資料中的上下文關聯性 (Contextual Dependency)**。

**原理架構**：

- CNN 輸出的特徵序列是有順序性的，從左到右對應著影像的內容。LSTM 的任務就是解讀這個特徵序列。
- **遺忘門 (Forget Gate)、輸入門 (Input Gate)、輸出門 (Output Gate)**：LSTM 透過這三個「門」的特殊設計，能有效地決定哪些資訊應該被遺忘、哪些新資訊應該被儲存，以及在當前時間點要輸出什麼。這解決了傳統 RNN 在處理長序列時會遇到的梯度消失或爆炸問題。
- **雙向 LSTM (Bidirectional LSTM, Bi-LSTM)**：在 OCR 中，一個字元的辨識不僅依賴其左側的上下文，也依賴其右側的上下文 (例如，要區分 "l" 和 "i"，右邊的字元很有幫助)。Bi-LSTM 會同時從前向後和從後向前處理序列，然後將兩個方向的資訊結合起來，提供更完整的上下文理解。

LSTM 層會接收 CNN 產生的特徵序列，並輸出一個新的序列。這個新序列的每個時間步都包含更豐富的上下文資訊，為最後的文字預測做準備。

## 3\. 連結主義時間分類 (CTC) - 對齊與解碼器

**功能**：CTC 損失函數是這個架構的精髓所在。它解決了 **輸入特徵序列與輸出文字標籤之間對齊 (Alignment) 的問題**，讓我們無需手動分割字元。

**背景問題**：
CNN+LSTM 輸出的結果是一個機率分佈序列，其長度與 CNN 輸出的特徵序列長度 $T$ 相同。然而，我們的目標輸出文字標籤 (例如 "HELLO") 的長度 $L$ 通常遠小於 $T$ ($L \\le T$)。如何將這個長度為 $T$ 的預測序列對應到長度為 $L$ 的目標標籤上？這就是對齊問題。

**CTC 原理**：

1.  **引入空白符號 (Blank Token, $\\epsilon$)**：CTC 在所有可能的字元類別 (如 'a' 到 'z') 之外，引入了一個特殊的「空白」符號。這個空白符號代表「非字元」。

2.  **路徑 (Path)**：CTC 模型輸出的序列中，每個時間步都會預測一個字元 (或空白符號)。因此，對於一個長度為 $T$ 的序列，就會有一條長度為 $T$ 的預測路徑 (Path)，例如 `[h, h, $\epsilon$, e, l, l, $\epsilon$, l, o, o]`。

3.  **路徑合併**：CTC 定義了一套規則來將這些路徑解碼成最終的文字標籤：

    - 首先，合併連續重複的字元。例如 `[h, h, ...]` 變成 `[h, ...]`。
    - 然後，移除所有的空白符號 $\\epsilon$。
    - 經過這兩步，上面的路徑 `[h, h, $\epsilon$, e, l, l, $\epsilon$, l, o, o]` 就會被解碼成 **"hello"**。

4.  **損失計算**：
    在訓練時，CTC 會計算所有可能產生正確目標標籤 (例如 "hello") 的路徑的 **總機率**。例如，`[h, e, l, l, o]`、`[h, $\epsilon$, e, l, l, o]` 和 `[h, h, e, l, $\epsilon$, l, o]` 都是可以解碼成 "hello" 的有效路徑。CTC 損失函數的目標就是 **最大化這個總機率**。透過動態規劃演算法，可以有效率地計算這個值，並反向傳播梯度來更新 CNN 和 LSTM 的權重。

**優點**：

- **端到端訓練**：整個模型可以一起訓練，無需預先分割字元。
- **對齊自由**：模型會自動學習如何將影像特徵與文字標籤對齊。
- **性能優越**：對於不規則、手寫或藝術字體，其表現遠超傳統方法。

## 總結

**CNN + LSTM + CTC** 架構徹底改變了 OCR 技術。它將 OCR 從一個複雜的多階段流程，轉變為一個統一、端到端的深度學習任務。

**整體流程摘要**

輸入影像 → CNN 擷取特徵 → LSTM 建立上下文 → CTC 解碼與學習對齊

| 模組 | 功能           | 備註                       |
| ---- | -------------- | -------------------------- |
| CNN  | 視覺特徵擷取   | 模型基底（如 ResNet、VGG） |
| LSTM | 建立時序語境   | 常用 BiLSTM 雙向模型       |
| CTC  | 解碼與損失函數 | 避免手動分割與對齊         |

- **CNN** 扮演「眼睛」的角色，負責看懂影像，提取出最關鍵的視覺特徵。
- **LSTM** 扮演「大腦」的角色，分析這些視覺特徵的序列關係，理解上下文。
- **CTC** 扮演「翻譯官」的角色，巧妙地將模型內部的序列化預測，解碼成人類可讀的最終文字，同時解決了棘手的對齊問題。
